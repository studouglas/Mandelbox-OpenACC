\documentclass[11pt]{article}

% Packages
\usepackage[margin=1.2in]{geometry}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{titling}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{makecell}
\usepackage{xcolor}
\lstset{language=C, breaklines=true, basicstyle=\footnotesize\ttfamily,keepspaces=true,showstringspaces=false,tabsize=2,
	stringstyle=\color{orange},commentstyle=\color{white!60!black},keywordstyle=\color{green!60!black}}

% Title Page -----------------------------------------------------------------
\title{
\LARGE CS 4F03 -- Distributed Systems:
\\\vspace{10mm}
\large \textbf{Final Project Report}
\vspace{40mm}
}
\author{
Stuart Douglas -- 1214422
\\Matthew Pagnan -- 1208693
\vspace{10mm}
}
\date{\vfill \today}
% End Title Page -------------------------------------------------------------
\setlength{\parindent}{0pt}

\begin{document}
\maketitle
\newpage
% =================== Section =================== 
\tableofcontents
\newpage

\section{Description of Parallelization}
\subsection{Overview}
The parallelization of the project is based off of the nested for-loop in \texttt{renderFractal} that iterates over each pixel in the output image, calculating the correct colour for that pixel based off of the passed parameters. When the loop is encountered, the necessary data from the CPU's memory is copied in. A kernel is then launched on the GPU, and each thread begins the processing for one pixel. Every function call within the kernel is run sequentially on the calling thread, with all subsequent routines from \emph{those} functions inlined. Finally, the image data is copied back to the CPUre.

\subsection{Vector3D}
Originally, a \texttt{vec3} was represented by a C++ class. We changed this implementation to a struct, and wrote macros to perform computations on the vector. There were a few macros originally included with the project, but many more had to be written to ensure all \texttt{vec3} operations could be run on the \texttt{vec3} struct. Using macros simplified integration with OpenACC, as routines are a relatively new feature and not fully robust yet.

\subsection{OpenACC Data}
The complex data that is private to each thread, such as the pixel data objects, the vectors storing the \texttt{colour} and the \texttt{to} vector for the pixel, and the double array containing the \texttt{farPoint} for the pixel are all stored in arrays, where each thread on the GPU accesses one element of each array. These values are not needed by the CPU at all, so the arrays are allocated on GPU memory using \texttt{acc\_malloc}, and declared as device pointers. Note that they are allocated once at the beginning of the program and freed just before the program exits.

%\subsection{Writing BMP to Disk}
%We observed that once the program renders an image, it must wait for the CPU to write that image to disk before continuing to the next frame. We introduced a simple optimization to allow execution to continue, so that the GPU can be rendering the next frame while the CPU is writing the previous one to the disk. This was a simple matter of creating a new thread to write the image out, then continuing to the next iteration for rendering, swapping out the image buffer with another. Once execution reaches the \texttt{saveBMP} call again, it waits for the ``write-out'' thread to finish, then spawns a new thread and continues. Having two image buffers does increase memory usage, but it allows both the host and device to do time-consuming work at the same time.

\section{Computing Parameters for Frames}\label{Sec_AutomaticNav}
Generating the camera parameters for the next frame is done automatically, based on the furthest point in the mandelbox. To do this, additional data needs to be stored about each point. Each GPU thread will know how far the point is that it hits from \texttt{rayMarch}, as well as the vector representing that point. After the kernel has finished executing, we need to find the furthest of such points. Initially, it seems intuitive to use an OpenACC \texttt{max} reduction to find this distance as all the distance data is stored on the GPU, but we need to know the vector associated with that maximum distance, which is not supported by a reduction. Instead, we copy an array storing the distances to each point back from the GPU when the kernel exits, and the CPU iterates through them to find the max. Once it does, we use \texttt{acc\_memcpy\_from\_device} to copy the single vector associated with that distance back, without copying the entire array of pixel data. This does reduce performance a little, but the difference is relatively minor.\\

After the new vector is found, execution returns to \texttt{main}, and the CPU calculates the camera position and target for the next frame. The camera always moves directly towards the currently set ``furthest point'', which may in fact be different than the camera's target. This is because the camera's target does not instantly snap to the new furthest point as soon as it's set. Instead the camera interpolates between where it was looking before and where it ``should'' be looking. Even though it's not looking directly at the new target, we still want it to follow the path towards that target, so as to prevent collisions. This essentially allows the camera to pan to face the new target so viewers can see not only the destination but they also get to see the environment around the camera. The camera will move towards the target until one of two things happen:
\begin{itemize}
\item The camera gets within a certain distance of the target point
\item The camera is looking directly at the target
\end{itemize}
The first condition is very obvious for why the camera will change targets, as we don't want to run into a wall. The second condition provides a more interesting video, by causing more camera movements rather than just locking on to a point and travelling in a straight line. That being said, it is undesirable to have the camera changing targets all the time, as the video would be extremely shaky. This is addressed by only allowing targets to change in the above two scenarios.

\section{Mandelbox Performance vs. Mandelbulb}
The reason the mandelbulb is faster to compute comes down to the distance estimator for mandelbulbs. Although we did not run the mandelbulb code, we can observe why it will be faster. Following is the disance estimator code for the mandelbox:
\lstinputlisting{mandelbox_de.cc}

And for the mandelbulb:
\lstinputlisting{mandelbulb_de.cc}

It can be seen that 

\section{Source Code}
The following source code files were not changed from the serial version of the program, and as such will their contents will not be reproduced in this document.
\begin{itemize}
\item \texttt{camera.h}
\item \texttt{color.h}
\item \texttt{getparams.c}
\item \texttt{init3D.cc}
\item \texttt{mandelbox.h}
\item \texttt{renderer.h}
\item \texttt{savebmp.c}
\end{itemize}

Due to OpenACC requirements for nested inline routines being in the same source file, the \texttt{MandelBoxDE} and \texttt{DE} functions were moved to \texttt{raymarching.cc}. Functions for printing progress and timing data were removed, as they were no longer deemed necessary due to the speedups from running the program on the GPU. As such, the following source code files were removed.
\begin{itemize}
\item \texttt{distance\_est.cc}
\item \texttt{mandelboxde.cc}
\item \texttt{print.c}
\item \texttt{timing.c}
\end{itemize}

Following are the modified source code files. Note that we made every effort to write ``self-documenting'' code by using clear variable names, so tried to limit comments within the source code to situations that are not immediately clear. Files are sorted alphabetically.

\subsection{getcolor.cc}
\lstinputlisting{../getcolor.cc}

\subsection{main.cc}
\lstinputlisting{../main.cc}

\subsection{raymarching.cc}
\lstinputlisting{../raymarching.cc}

\subsection{renderer.cc}
\lstinputlisting{../renderer.cc}

\subsection{vector3d.h}
\lstinputlisting{../vector3d.h}

\subsection{3d.cc}
\lstinputlisting{../3d.cc}

\subsection{3d.h}
\lstinputlisting{../3d.h}

\section{Running the Program}
To generate the video, follow the following steps.
\begin{enumerate}
\item Run \texttt{make mandelbox} from the project directory
\item Execute the program with \texttt{./mandelbox params.dat}
\item Convert the images to a video by running \texttt{./convert\_to\_video}
\end{enumerate}

If you wish to change the number of frames, simply open \texttt{main.cc} and replace the value for the \texttt{NUM\_FRAMES} pragma with the desired number of frames.

\section{Bonus Features}
\subsection{Automatic Navigation}
The automatic navigation functionality for the project was implemented. That is, the program will determine a path through the mandelbox that does not ``hit'' any walls, nor leave the box itself. For more details on the algorithm used, refer to section \ref{Sec_AutomaticNav}.

\end{document}